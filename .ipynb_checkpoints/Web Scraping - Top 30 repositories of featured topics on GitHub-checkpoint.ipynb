{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949f075f",
   "metadata": {},
   "source": [
    "# Web Scraping - Top 30 repositories of featured topics on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26b7a6",
   "metadata": {},
   "source": [
    "## Scraping top 30 repositories for top 30 featured topics on GitHub\n",
    "\n",
    "\n",
    "1. Scraping https://github.com/topics to collect a list of topics form GitHub.\n",
    "2. Extracting the topic title, topic page URL and topic description for each topic.\n",
    "3. Extracting top 30 repositories from the list of topics from the topic page.\n",
    "4. Collecting repository name, username, stars and repository URL for each repository.\n",
    "5. We will create a seperate CSV file for each topic in the below format -\n",
    "\n",
    "   username,repo_name,stars,repo_url\n",
    "   mrdoob,three.js,79400,https://github.com/mrdoob/three.js\n",
    "   libgdx,libgdx,19700,https://github.com/libgdx/libgdx\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf1031",
   "metadata": {},
   "source": [
    "## Steps followed for scraping:\n",
    "    - Use requests module to download the page for scraping.\n",
    "    - Use bs4 to parse and extract the data.\n",
    "    - Convert the collected data into a Pandas DataFrame and save it as a \n",
    "      csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb3cc9",
   "metadata": {},
   "source": [
    "- Importing the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9921ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc81f7d",
   "metadata": {},
   "source": [
    "### Creating a function for grabbing the topics page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad0ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page():\n",
    "    topic_url=\"https://github.com/topics\"\n",
    "    response = requests.get(topic_url)\n",
    "    # Adding a condition to execute if the response is not successful or the page fails to load.\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Failed to load page {topic_url}')\n",
    "        # Parsing the html code from the requested page.\n",
    "    doc=BeautifulSoup(response.text,'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be29e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=get_topic_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0f2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Writing a function for collecting all the 'p' tags with\n",
    "class \"f3 lh-condensed mb-0 mt-1 Link--primary\" to grab the topic titles.'''\n",
    "\n",
    "def get_topic_titles(doc):\n",
    "    title_class=\"f3 lh-condensed mb-0 mt-1 Link--primary\"\n",
    "    topic_title_tags=doc.find_all('p',{'class':title_class})\n",
    "    topic_titles=[]\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d5b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1371027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979f0ec",
   "metadata": {},
   "source": [
    "We have extracted the titles from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eddd538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e1d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Writing a function for collecting all the 'p' tags with\n",
    "class \"f5 color-fg-muted mb-0 mt-1\" to grab the description for each topic.'''\n",
    "\n",
    "def get_topic_desc(doc):\n",
    "    desc_class=\"f5 color-fg-muted mb-0 mt-1\"\n",
    "    topic_desc_tags=doc.find_all('p',{'class':desc_class})\n",
    "    topic_descriptions=[]\n",
    "    for descriptions in topic_desc_tags:\n",
    "        topic_descriptions.append(descriptions.text.strip())\n",
    "    return topic_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c74d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions=get_topic_desc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60eaf819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3fa2e",
   "metadata": {},
   "source": [
    "- We have extracted the descriptions from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd4082f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3D modeling is the process of virtually developing the surface and structure of a 3D object.',\n",
       " 'Ajax is a technique for creating interactive web applications.',\n",
       " 'Algorithms are self-contained sequences that carry out a variety of tasks.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cba1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Writing a function for collecting all the 'a' tags with\n",
    "class \"no-underline flex-1 d-flex flex-column\" to grab the link for each topic page.'''\n",
    "\n",
    "def get_topic_urls(doc):\n",
    "    topic_link_class=\"no-underline flex-1 d-flex flex-column\"\n",
    "    topic_link_tags=doc.findAll('a',{'class':topic_link_class})\n",
    "    topic_urls=[]\n",
    "    base_url=\"https://github.com\"\n",
    "    for urls in topic_link_tags:\n",
    "        topic_urls.append(base_url+urls['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eba3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_urls=get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "703ca375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7130e07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/3d',\n",
       " 'https://github.com/topics/ajax',\n",
       " 'https://github.com/topics/algorithm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_urls[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429b45c",
   "metadata": {},
   "source": [
    "### Creating a single function which will return the title, description and link for the topics as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da7d62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b219f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topics_url='https://github.com/topics'\n",
    "    response=requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception (f'Failed to load page {topics_url}')\n",
    "    topics_dict={\n",
    "        'title':get_topic_titles(doc),\n",
    "        'description':get_topic_desc(doc),\n",
    "        'url':get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e4e141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df=scrape_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c72df78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d3f39ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D modeling is the process of virtually develo...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D modeling is the process of virtually develo...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b48fb",
   "metadata": {},
   "source": [
    "## Creating a function to grab the topic page for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "216c1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # Parse using Beautiful soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c03ba868",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Writing a function for collecting all the  tags for\n",
    "grabbing the information for a repository.'''\n",
    "def get_repo_info(h1_tag, star_tag):\n",
    "    # returns all the required info about a repository\n",
    "    a_tags = h1_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url =  base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dc0e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h1 tags containing repo title, repo URL and username\n",
    "    h1_selection_class = 'f3 color-text-secondary text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h1', {'class': h1_selection_class} )\n",
    "    # Get star_tags\n",
    "    star_tags = topic_doc.find_all('a', { 'class': 'social-count float-none'})\n",
    "    ''' Creating a dictionary of the information of\n",
    "        repositories for converting it into a dataframe.'''\n",
    "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
    "\n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76b98dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e4173b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing a function to save every dataframe as a csv.\n",
    "def scrape_topic(topic_url,path):\n",
    "    #Adding a condition to skip the file if it already exists.\n",
    "    if os.path.exists(path):\n",
    "        print(f\"The file {path} already exists. Skipping...\")\n",
    "        return\n",
    "    topic_df=get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435c6e9",
   "metadata": {},
   "source": [
    "## Creating a single function which will create a seperate  csv file for every topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25a067c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print(\"Scraping list of topics\")\n",
    "    topics_df=scrape_topics()\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    for index,row in topics_df.iterrows():\n",
    "        print(f\"Scraping top repositories for {row['title']}\")\n",
    "        scrape_topic(row['url'],\"data/{}.csv\".format(row['title']))\n",
    "    print('\\nDone!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b31de38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for 3D\n",
      "The file data/3D.csv already exists. Skipping...\n",
      "Scraping top repositories for Ajax\n",
      "The file data/Ajax.csv already exists. Skipping...\n",
      "Scraping top repositories for Algorithm\n",
      "The file data/Algorithm.csv already exists. Skipping...\n",
      "Scraping top repositories for Amp\n",
      "The file data/Amp.csv already exists. Skipping...\n",
      "Scraping top repositories for Android\n",
      "The file data/Android.csv already exists. Skipping...\n",
      "Scraping top repositories for Angular\n",
      "The file data/Angular.csv already exists. Skipping...\n",
      "Scraping top repositories for Ansible\n",
      "The file data/Ansible.csv already exists. Skipping...\n",
      "Scraping top repositories for API\n",
      "The file data/API.csv already exists. Skipping...\n",
      "Scraping top repositories for Arduino\n",
      "The file data/Arduino.csv already exists. Skipping...\n",
      "Scraping top repositories for ASP.NET\n",
      "The file data/ASP.NET.csv already exists. Skipping...\n",
      "Scraping top repositories for Atom\n",
      "The file data/Atom.csv already exists. Skipping...\n",
      "Scraping top repositories for Awesome Lists\n",
      "The file data/Awesome Lists.csv already exists. Skipping...\n",
      "Scraping top repositories for Amazon Web Services\n",
      "The file data/Amazon Web Services.csv already exists. Skipping...\n",
      "Scraping top repositories for Azure\n",
      "The file data/Azure.csv already exists. Skipping...\n",
      "Scraping top repositories for Babel\n",
      "The file data/Babel.csv already exists. Skipping...\n",
      "Scraping top repositories for Bash\n",
      "The file data/Bash.csv already exists. Skipping...\n",
      "Scraping top repositories for Bitcoin\n",
      "The file data/Bitcoin.csv already exists. Skipping...\n",
      "Scraping top repositories for Bootstrap\n",
      "The file data/Bootstrap.csv already exists. Skipping...\n",
      "Scraping top repositories for Bot\n",
      "The file data/Bot.csv already exists. Skipping...\n",
      "Scraping top repositories for C\n",
      "The file data/C.csv already exists. Skipping...\n",
      "Scraping top repositories for Chrome\n",
      "The file data/Chrome.csv already exists. Skipping...\n",
      "Scraping top repositories for Chrome extension\n",
      "Scraping top repositories for Command line interface\n",
      "Scraping top repositories for Clojure\n",
      "Scraping top repositories for Code quality\n",
      "Scraping top repositories for Code review\n",
      "Scraping top repositories for Compiler\n",
      "Scraping top repositories for Continuous integration\n",
      "Scraping top repositories for COVID-19\n",
      "Scraping top repositories for C++\n",
      "\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7f45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
